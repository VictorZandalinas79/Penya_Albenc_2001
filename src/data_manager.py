"""
Gestor de datos para PENYA L'ALBENC
Maneja la lectura, escritura y operaciones con archivos Parquet
"""

import pandas as pd
import logging
from datetime import date, datetime
from pathlib import Path
import shutil
from typing import Dict, Any, Optional
from config import Config

logger = logging.getLogger(__name__)

class DataManager:
    """Clase para gestionar los datos de la aplicaci√≥n"""
    
    def __init__(self):
        """Inicializar el gestor de datos"""
        self.config = Config()
        self._ensure_directories()
    
    def _ensure_directories(self):
        """Asegurar que existen todos los directorios necesarios"""
        self.config.DATA_FOLDER.mkdir(exist_ok=True)
        self.config.BACKUP_FOLDER.mkdir(exist_ok=True)
        logger.info(f"üìÅ Directorios verificados: {self.config.DATA_FOLDER}")
    
    def create_backup(self, filename: str) -> bool:
        """
        Crear backup de un archivo antes de modificarlo
        
        Args:
            filename: Nombre del archivo a respaldar
            
        Returns:
            bool: True si el backup fue exitoso
        """
        try:
            source_file = self.config.DATA_FOLDER / filename
            if source_file.exists():
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_name = f"{filename.replace('.parquet', '')}_{timestamp}.parquet"
                backup_file = self.config.BACKUP_FOLDER / backup_name
                
                shutil.copy2(source_file, backup_file)
                logger.info(f"üíæ Backup creado: {backup_name}")
                
                # Limpiar backups antiguos
                self._cleanup_old_backups(filename.replace('.parquet', ''))
                return True
        except Exception as e:
            logger.error(f"‚ùå Error creando backup de {filename}: {e}")
            return False
    
    def _cleanup_old_backups(self, base_filename: str):
        """Limpiar backups antiguos manteniendo solo los m√°s recientes"""
        try:
            backup_files = list(self.config.BACKUP_FOLDER.glob(f"{base_filename}_*.parquet"))
            backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            # Eliminar backups antiguos si hay m√°s del m√°ximo permitido
            for old_backup in backup_files[self.config.MAX_BACKUPS:]:
                old_backup.unlink()
                logger.info(f"üóëÔ∏è Backup antiguo eliminado: {old_backup.name}")
                
        except Exception as e:
            logger.error(f"‚ùå Error limpiando backups: {e}")
    
    def save_dataframe(self, df: pd.DataFrame, filename: str) -> bool:
        """
        Guardar DataFrame en archivo Parquet con backup
        
        Args:
            df: DataFrame a guardar
            filename: Nombre del archivo
            
        Returns:
            bool: True si el guardado fue exitoso
        """
        try:
            file_path = self.config.DATA_FOLDER / filename
            
            # Crear backup si el archivo existe
            if file_path.exists() and self.config.BACKUP_ENABLED:
                self.create_backup(filename)
            
            # Guardar el archivo
            df.to_parquet(file_path, index=False)
            logger.info(f"üíæ Datos guardados en {filename}: {len(df)} registros")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error guardando {filename}: {e}")
            return False
    
    def load_dataframe(self, filename: str) -> pd.DataFrame:
        """
        Cargar DataFrame desde archivo Parquet
        
        Args:
            filename: Nombre del archivo a cargar
            
        Returns:
            pd.DataFrame: DataFrame cargado o vac√≠o si hay error
        """
        try:
            file_path = self.config.DATA_FOLDER / filename
            
            if file_path.exists():
                df = pd.read_parquet(file_path)
                logger.info(f"üìñ Datos cargados de {filename}: {len(df)} registros")
                return df
            else:
                logger.warning(f"‚ö†Ô∏è Archivo no encontrado: {filename}")
                return self._create_empty_dataframe(filename)
                
        except Exception as e:
            logger.error(f"‚ùå Error cargando {filename}: {e}")
            return self._create_empty_dataframe(filename)
    
    def _create_empty_dataframe(self, filename: str) -> pd.DataFrame:
        """Crear DataFrame vac√≠o seg√∫n el tipo de archivo"""
        
        schemas = {
            'comidas.parquet': {
                'fecha': pd.Series([], dtype='datetime64[ns]'),
                'tipo_evento': pd.Series([], dtype='object'),
                'tipo_comida': pd.Series([], dtype='object'),
                'cocineros': pd.Series([], dtype='object')
            },
            'lista_compra.parquet': {
                'fecha': pd.Series([], dtype='datetime64[ns]'),
                'articulos': pd.Series([], dtype='object')
            },
            'mantenimiento.parquet': {
                'a√±o': pd.Series([], dtype='int64'),
                'mantenimiento': pd.Series([], dtype='object'),
                'cadafals': pd.Series([], dtype='object')
            },
            'fiestas.parquet': {
                'fecha': pd.Series([], dtype='datetime64[ns]'),
                'tipo_fiesta': pd.Series([], dtype='object'),
                'encargados_cocina': pd.Series([], dtype='object'),
                'menu_cena': pd.Series([], dtype='object')
            },
            'cambios_log.parquet': {
                'timestamp': pd.Series([], dtype='datetime64[ns]'),
                'seccion': pd.Series([], dtype='object'),
                'tipo_cambio': pd.Series([], dtype='object'),
                'descripcion': pd.Series([], dtype='object'),
                'usuario': pd.Series([], dtype='object')
            }
        }
        
        if filename in schemas:
            return pd.DataFrame(schemas[filename])
        else:
            logger.warning(f"‚ö†Ô∏è Schema no definido para {filename}")
            return pd.DataFrame()

# Instancia global del gestor de datos
data_manager = DataManager()

def log_cambio(seccion, tipo_cambio, descripcion, usuario='sistema'):
    """Registrar un cambio en el log"""
    try:
        from datetime import datetime
        
        # Cargar log existente o crear nuevo
        try:
            log_df = data_manager.load_dataframe('cambios_log.parquet')
        except:
            log_df = pd.DataFrame({
                'timestamp': [],
                'seccion': [],
                'tipo_cambio': [],
                'descripcion': [],
                'usuario': []
            })
        
        # Agregar nuevo cambio
        nuevo_cambio = pd.DataFrame({
            'timestamp': [datetime.now()],
            'seccion': [seccion],
            'tipo_cambio': [tipo_cambio],
            'descripcion': [descripcion],
            'usuario': [usuario]
        })
        
        log_df = pd.concat([log_df, nuevo_cambio], ignore_index=True)
        
        # Mantener solo los √∫ltimos 100 cambios
        if len(log_df) > 100:
            log_df = log_df.tail(100)
        
        data_manager.save_dataframe(log_df, 'cambios_log.parquet')
        logger.info(f"üìù Cambio registrado: {seccion} - {tipo_cambio}")
        
    except Exception as e:
        logger.error(f"Error registrando cambio: {e}")

def obtener_ultimos_cambios(n=10):
    """Obtener los √∫ltimos N cambios"""
    try:
        log_df = data_manager.load_dataframe('cambios_log.parquet')
        if len(log_df) == 0:
            return []
        
        # Ordenar por timestamp descendente y tomar los √∫ltimos N
        log_df = log_df.sort_values('timestamp', ascending=False).head(n)
        return log_df.to_dict('records')
    except:
        return []

def force_update_real_data():
    """Forzar la actualizaci√≥n con datos reales del PDF"""
    logger.info("üîÑ Forzando actualizaci√≥n con datos reales del PDF...")
    
    # Importar el calculador de fechas
    from src.fecha_calculator import generar_fechas_fiestas, obtener_datos_a√±o, obtener_todos_los_a√±os
    
    # Crear backup de datos existentes si existen
    for archivo in ['mantenimiento.parquet', 'comidas.parquet']:
        archivo_path = Config.DATA_FOLDER / archivo
        if archivo_path.exists():
            data_manager.create_backup(archivo)
    
    # FORZAR actualizaci√≥n de mantenimiento
    logger.info("üìã Actualizando mantenimiento con datos reales...")
    a√±os = obtener_todos_los_a√±os()
    mantenimiento_data = []
    
    for a√±o in a√±os:
        datos_a√±o = obtener_datos_a√±o(a√±o)
        mantenimiento_data.append({
            'a√±o': a√±o,
            'mantenimiento': datos_a√±o.get('manteniment', ''),
            'cadafals': datos_a√±o.get('cadafals', '')
        })
    
    mant_df = pd.DataFrame(mantenimiento_data)
    data_manager.save_dataframe(mant_df, 'mantenimiento.parquet')
    log_cambio('Mantenimiento', 'Actualizaci√≥n masiva', f'Cargados {len(mant_df)} a√±os del PDF (2025-2045)')
    logger.info(f"‚úÖ Mantenimiento actualizado: {len(mant_df)} a√±os (2025-2045)")
    
    # FORZAR actualizaci√≥n de COMIDAS con nueva estructura de 4 columnas
    logger.info("üçΩÔ∏è Actualizando comidas con nueva estructura (4 columnas)...")
    comidas_data = []
    
    from datetime import timedelta
    
    for a√±o in a√±os:
        fechas_a√±o = generar_fechas_fiestas(a√±o)
        datos_a√±o = obtener_datos_a√±o(a√±o)
        
        # Sant Antoni (tercer s√°bado enero - solo cena)
        if 'sant_antoni' in fechas_a√±o and 'sant_antoni' in datos_a√±o:
            comidas_data.append({
                'fecha': fechas_a√±o['sant_antoni'],
                'tipo_evento': 'Sant Antoni',
                'tipo_comida': 'Cena',
                'cocineros': datos_a√±o['sant_antoni']
            })
        
        # Brena St Vicent (s√°bado cercano 28 abril - comida y cena)
        if 'brena_st_vicent' in fechas_a√±o and 'brena_st_vicent' in datos_a√±o:
            comidas_data.append({
                'fecha': fechas_a√±o['brena_st_vicent'],
                'tipo_evento': 'Brena St Vicent',
                'tipo_comida': 'Comida y Cena',
                'cocineros': datos_a√±o['brena_st_vicent']
            })
        
        # Fira Magdalena (tercer s√°bado julio - comida y cena)
        if 'fira_magdalena' in fechas_a√±o and 'fira_magdalena' in datos_a√±o:
            comidas_data.append({
                'fecha': fechas_a√±o['fira_magdalena'],
                'tipo_evento': 'Fira Magdalena',
                'tipo_comida': 'Comida y Cena',
                'cocineros': datos_a√±o['fira_magdalena']
            })
        
        # Penya Taurina (√∫ltimo s√°bado mayo - solo comida)
        if 'penya_taurina' in fechas_a√±o and 'penya_taurina' in datos_a√±o:
            comidas_data.append({
                'fecha': fechas_a√±o['penya_taurina'],
                'tipo_evento': 'Penya Taurina',
                'tipo_comida': 'Comida',
                'cocineros': datos_a√±o['penya_taurina']
            })
    
    # Agregar algunas comidas adicionales de semana normal con rotaci√≥n
    base_date = date.today()
    encargados_rotacion = [
        "David, Juan Fernando", "Diego, Miguel A.", "Xisco, Serafin", 
        "Juan Ramon, Oscar", "Alfonso, Victor Z.", "Miguel A., Raul A.", 
        "Lluis, Alonso", "Victor M., Raul M."
    ]
    
    # Agregar comidas de semana para las pr√≥ximas 4 semanas
    for i in range(28):
        fecha = base_date + timedelta(days=i)
        # Solo d√≠as laborables (lunes a viernes) para comidas normales
        if fecha.weekday() < 5:  # Lunes a viernes
            # Verificar que no coincida con fechas especiales ya agregadas
            fecha_existente = any(
                item['fecha'] == fecha 
                for item in comidas_data
            )
            if not fecha_existente:
                comidas_data.append({
                    'fecha': fecha,
                    'tipo_evento': 'Comida Normal',
                    'tipo_comida': 'Comida',
                    'cocineros': encargados_rotacion[i % len(encargados_rotacion)]
                })
    
    comidas_df = pd.DataFrame(comidas_data)
    comidas_df = comidas_df.sort_values('fecha')
    data_manager.save_dataframe(comidas_df, 'comidas.parquet')
    log_cambio('Comidas', 'Actualizaci√≥n masiva', f'Cargadas {len(comidas_df)} comidas con nueva estructura 4 columnas')
    logger.info(f"‚úÖ Comidas actualizadas: {len(comidas_df)} registros con nueva estructura")
    
    # LIMPIAR fiestas (dejar vac√≠o para eventos especiales futuros)
    logger.info("üéâ Limpiando fiestas (quedar√° vac√≠o para eventos especiales futuros)...")
    fiestas_df = pd.DataFrame({
        'fecha': [],
        'tipo_fiesta': [],
        'encargados_cocina': [],
        'menu_cena': []
    })
    data_manager.save_dataframe(fiestas_df, 'fiestas.parquet')
    log_cambio('Fiestas', 'Limpieza', 'Tabla vaciada para eventos especiales futuros')
    logger.info("‚úÖ Fiestas limpiadas (vac√≠as para eventos especiales futuros)")
    
    return len(mant_df), len(comidas_df)

def create_initial_data():
    """Crear archivos de datos iniciales con datos reales de PENYA L'ALBENC y nueva estructura"""
    logger.info("üîß Creando datos reales de PENYA L'ALBENC con nueva estructura...")
    
    # Importar el calculador de fechas
    from src.fecha_calculator import generar_fechas_fiestas, obtener_datos_a√±o, obtener_todos_los_a√±os
    
    # SIEMPRE crear/actualizar mantenimiento con datos reales del PDF
    logger.info("üìã Creando datos de mantenimiento reales...")
    a√±os = obtener_todos_los_a√±os()
    mantenimiento_data = []
    
    for a√±o in a√±os:
        datos_a√±o = obtener_datos_a√±o(a√±o)
        mantenimiento_data.append({
            'a√±o': a√±o,
            'mantenimiento': datos_a√±o.get('manteniment', ''),
            'cadafals': datos_a√±o.get('cadafals', '')
        })
    
    mant_df = pd.DataFrame(mantenimiento_data)
    data_manager.save_dataframe(mant_df, 'mantenimiento.parquet')
    log_cambio('Mantenimiento', 'Inicializaci√≥n', f'Creados {len(mant_df)} a√±os del PDF')
    logger.info(f"‚úÖ Mantenimiento: {len(mant_df)} a√±os creados (2025-2045) con datos reales")
    
    # CREAR comidas con nueva estructura de 4 columnas
    logger.info("üçΩÔ∏è Creando comidas con nueva estructura de 4 columnas...")
    comidas_data = []
    
    from datetime import timedelta
    
    # Primero, agregar las fechas especiales del PDF
    for a√±o in [2025, 2026, 2027]:  # Solo algunos a√±os iniciales
        fechas_a√±o = generar_fechas_fiestas(a√±o)
        datos_a√±o = obtener_datos_a√±o(a√±o)
        
        # Sant Antoni (solo cena)
        if 'sant_antoni' in fechas_a√±o and 'sant_antoni' in datos_a√±o:
            comidas_data.append({
                'fecha': fechas_a√±o['sant_antoni'],
                'tipo_evento': 'Sant Antoni',
                'tipo_comida': 'Cena',
                'cocineros': datos_a√±o['sant_antoni']
            })
        
        # Brena St Vicent (comida y cena)
        if 'brena_st_vicent' in fechas_a√±o and 'brena_st_vicent' in datos_a√±o:
            comidas_data.append({
                'fecha': fechas_a√±o['brena_st_vicent'],
                'tipo_evento': 'Brena St Vicent',
                'tipo_comida': 'Comida y Cena',
                'cocineros': datos_a√±o['brena_st_vicent']
            })
        
        # Fira Magdalena (comida y cena)
        if 'fira_magdalena' in fechas_a√±o and 'fira_magdalena' in datos_a√±o:
            comidas_data.append({
                'fecha': fechas_a√±o['fira_magdalena'],
                'tipo_evento': 'Fira Magdalena',
                'tipo_comida': 'Comida y Cena',
                'cocineros': datos_a√±o['fira_magdalena']
            })
        
        # Penya Taurina (solo comida)
        if 'penya_taurina' in fechas_a√±o and 'penya_taurina' in datos_a√±o:
            comidas_data.append({
                'fecha': fechas_a√±o['penya_taurina'],
                'tipo_evento': 'Penya Taurina',
                'tipo_comida': 'Comida',
                'cocineros': datos_a√±o['penya_taurina']
            })
    
    # Luego, agregar comidas normales de semana
    base_date = date.today()
    encargados_rotacion = [
        "David, Juan Fernando", "Diego, Miguel A.", "Xisco, Serafin", 
        "Juan Ramon, Oscar", "Alfonso, Victor Z.", "Miguel A., Raul A.", 
        "Lluis, Alonso", "Victor M., Raul M."
    ]
    
    # Agregar 4 semanas de comidas normales
    for i in range(28):
        fecha = base_date + timedelta(days=i)
        # Solo d√≠as laborables para comidas normales
        if fecha.weekday() < 5:  # Lunes a viernes
            # Verificar que no coincida con fechas especiales
            fecha_existente = any(
                item['fecha'] == fecha 
                for item in comidas_data
            )
            if not fecha_existente:
                comidas_data.append({
                    'fecha': fecha,
                    'tipo_evento': 'Comida Normal',
                    'tipo_comida': 'Comida',
                    'cocineros': encargados_rotacion[i % len(encargados_rotacion)]
                })
        
        # Cenas de fin de semana
        if fecha.weekday() >= 4:  # Viernes a domingo
            fecha_existente = any(
                item['fecha'] == fecha 
                for item in comidas_data
            )
            if not fecha_existente:
                comidas_data.append({
                    'fecha': fecha,
                    'tipo_evento': 'Comida Normal',
                    'tipo_comida': 'Cena',
                    'cocineros': encargados_rotacion[(i+1) % len(encargados_rotacion)]
                })
    
    comidas_df = pd.DataFrame(comidas_data)
    comidas_df = comidas_df.sort_values('fecha')
    data_manager.save_dataframe(comidas_df, 'comidas.parquet')
    log_cambio('Comidas', 'Inicializaci√≥n', f'Creadas {len(comidas_df)} comidas con estructura 4 columnas')
    logger.info(f"‚úÖ Comidas: {len(comidas_df)} registros creados con nueva estructura 4 columnas")
    
    # FIESTAS: Dejar vac√≠o para eventos especiales futuros
    logger.info("üéâ Creando tabla de fiestas vac√≠a (para eventos especiales futuros)...")
    fiestas_df = pd.DataFrame({
        'fecha': [],
        'tipo_fiesta': [],
        'encargados_cocina': [],
        'menu_cena': []
    })
    data_manager.save_dataframe(fiestas_df, 'fiestas.parquet')
    log_cambio('Fiestas', 'Inicializaci√≥n', 'Tabla vac√≠a creada para eventos especiales')
    logger.info("‚úÖ Fiestas: Tabla vac√≠a creada (lista para eventos especiales)")
    
    # Crear datos b√°sicos para lista de compra (solo si no existe)
    if not Config.LISTA_COMPRA_FILE.exists():
        logger.info("üõí Creando datos de lista de compra b√°sicos...")
        from datetime import timedelta
        
        compras_data = [
            (date.today() - timedelta(days=3), "Pan, Leche, Huevos, Aceite de oliva"),
            (date.today() - timedelta(days=2), "Tomates, Cebolla, Ajo, Pimientos"),
            (date.today() - timedelta(days=1), "Arroz, Lentejas, Garbanzos, Pasta"),
            (date.today(), "Pollo, Pescado, Ternera, Cerdo"),
            (date.today() + timedelta(days=1), "Yogur, Queso, Mantequilla, Nata"),
            (date.today() + timedelta(days=2), "Manzanas, Pl√°tanos, Naranjas, Limones"),
            (date.today() + timedelta(days=3), "Patatas, Zanahorias, Calabac√≠n, Br√≥coli"),
            (date.today() + timedelta(days=4), "Detergente, Papel higi√©nico, Servilletas"),
        ]
        
        lista_df = pd.DataFrame({
            'fecha': [item[0] for item in compras_data],
            'articulos': [item[1] for item in compras_data]
        })
        data_manager.save_dataframe(lista_df, 'lista_compra.parquet')
        log_cambio('Lista Compra', 'Inicializaci√≥n', f'Creadas {len(lista_df)} entradas b√°sicas')
        logger.info(f"‚úÖ Lista de compra: {len(lista_df)} registros creados")

def load_all_data() -> Dict[str, pd.DataFrame]:
    """
    Cargar todos los datos de la aplicaci√≥n
    
    Returns:
        Dict con todos los DataFrames
    """
    return {
        'comidas': data_manager.load_dataframe('comidas.parquet'),
        'lista_compra': data_manager.load_dataframe('lista_compra.parquet'),
        'mantenimiento': data_manager.load_dataframe('mantenimiento.parquet'),
        'fiestas': data_manager.load_dataframe('fiestas.parquet')
    }

def save_data(df: pd.DataFrame, data_type: str) -> bool:
    """
    Guardar datos seg√∫n el tipo
    
    Args:
        df: DataFrame a guardar
        data_type: Tipo de datos ('comidas', 'lista_compra', 'mantenimiento', 'fiestas')
        
    Returns:
        bool: True si fue exitoso
    """
    filename_map = {
        'comidas': 'comidas.parquet',
        'lista_compra': 'lista_compra.parquet',
        'mantenimiento': 'mantenimiento.parquet',
        'fiestas': 'fiestas.parquet'
    }
    
    if data_type in filename_map:
        return data_manager.save_dataframe(df, filename_map[data_type])
    else:
        logger.error(f"‚ùå Tipo de datos no v√°lido: {data_type}")
        return False

def get_data_stats() -> Dict[str, Any]:
    """
    Obtener estad√≠sticas de los datos
    
    Returns:
        Dict con estad√≠sticas de cada tabla
    """
    data = load_all_data()
    stats = {}
    
    for key, df in data.items():
        stats[key] = {
            'total_records': len(df),
            'columns': list(df.columns),
            'last_modified': Config.DATA_FOLDER.joinpath(f"{key}.parquet").stat().st_mtime if Config.DATA_FOLDER.joinpath(f"{key}.parquet").exists() else None
        }
    
    return stats

def export_data_to_csv(output_dir: Optional[str] = None) -> bool:
    """
    Exportar todos los datos a archivos CSV
    
    Args:
        output_dir: Directorio de salida (opcional)
        
    Returns:
        bool: True si fue exitoso
    """
    try:
        if output_dir:
            output_path = Path(output_dir)
        else:
            output_path = Config.DATA_FOLDER / 'exports'
        
        output_path.mkdir(exist_ok=True)
        
        data = load_all_data()
        for key, df in data.items():
            csv_file = output_path / f"{key}.csv"
            df.to_csv(csv_file, index=False)
            logger.info(f"üìÑ Exportado: {csv_file}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error exportando datos: {e}")
        return False